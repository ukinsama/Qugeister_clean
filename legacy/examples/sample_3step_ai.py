#!/usr/bin/env python3
"""
3Step AI Recipe: Auto-Generated Quantum Model
量子回路勾配伝播対応AI（3stepシステム自動生成）
生成日時: 2025/9/3 19:41:03
戦略: balanced
量子ビット数: 8
量子層数: 3
学習方法: reinforcement
"""

import torch
import torch.nn as nn
import numpy as np
try:
    import pennylane as qml
    PENNYLANE_AVAILABLE = True
except ImportError:
    PENNYLANE_AVAILABLE = False
    print("⚠️ PennyLane not available, using simulation")

class QuantumLayerWithGradient(nn.Module):
    """勾配伝播可能な量子層"""
    def __init__(self, n_qubits=8, n_layers=3):
        super().__init__()
        self.n_qubits = n_qubits
        self.n_layers = n_layers
        
        if PENNYLANE_AVAILABLE:
            self.dev = qml.device('default.qubit', wires=n_qubits)
            self.quantum_weights = nn.Parameter(
                torch.randn(n_layers * n_qubits * 2, requires_grad=True) * 0.1
            )
            
            @qml.qnode(self.dev, interface='torch', diff_method='backprop')
            def quantum_circuit(inputs, weights):
                weights = weights.reshape(n_layers, n_qubits, 2)
                
                # データエンコーディング (angle)
                for i in range(min(len(inputs), n_qubits)):
                    qml.RY(inputs[i], wires=i)
                
                # パラメータ化層
                for l in range(n_layers):
                    for i in range(n_qubits):
                        qml.RY(weights[l, i, 0], wires=i)
                        qml.RZ(weights[l, i, 1], wires=i)
                    
                    # エンタングルメント (linear)
                    for i in range(n_qubits - 1):
                        qml.CNOT(wires=[i, i+1])
                
                return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]
            
            self.quantum_circuit = quantum_circuit
        else:
            self.quantum_weights = nn.Parameter(torch.randn(n_layers, n_qubits, 2) * 0.1)
    
    def forward(self, x):
        if x.dim() == 1:
            x = x.unsqueeze(0)
        
        if PENNYLANE_AVAILABLE:
            outputs = []
            for i in range(x.size(0)):
                normalized_input = torch.tanh(x[i][:self.n_qubits]) * np.pi
                output = self.quantum_circuit(normalized_input, self.quantum_weights)
                if isinstance(output, list):
                    output = torch.stack(output)
                output = output.float()
                outputs.append(output)
            return torch.stack(outputs)
        else:
            return torch.tanh(x[:, :self.n_qubits])

class AutoGeneratedQuantumModel(nn.Module):
    """自動生成された量子AI (balanced戦略)"""
    def __init__(self):
        super().__init__()
        
        # 戦略バイアス
        self.strategy_bias = nn.Parameter(torch.zeros(4))  # バランス型
        
        self.classical_encoder = nn.Sequential(
            nn.Linear(36, 64),  # 6x6ボード
            nn.ReLU(),
            nn.Linear(64, 8)
        )
        
        self.quantum_layer = QuantumLayerWithGradient(n_qubits=8, n_layers=3)
        
        self.intermediate = nn.Sequential(
            nn.Linear(8, 32),
            nn.ReLU(),
            nn.Linear(32, 32)
        )
        
        self.action_head = nn.Sequential(
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 4)  # 4方向
        )
    
    def forward(self, x):
        if x.dim() == 1:
            x = x.unsqueeze(0)
        
        classical_features = self.classical_encoder(x)
        quantum_features = self.quantum_layer(classical_features)
        intermediate_features = self.intermediate(quantum_features)
        action_values = self.action_head(intermediate_features)
        action_values = action_values + self.strategy_bias
        
        return action_values

# ===== 学習設定 =====
config = {
    'strategy': 'balanced',
    'learning_rate': 0.001,
    'batch_size': 32,
    'episodes': 1000,
    'epsilon': 0.1
}

def get_ai_config():
    """学習システム用のAI設定を返す"""
    return {
        'name': 'test02',
        'type': 'quantum_grad',
        'learning_rate': 0.001,
        'epochs': 100,
        'batch_size': 32,
        'description': '3step Designer Quantum AI (balanced)',
        'strategy': 'balanced',
        'n_qubits': 8,
        'n_layers': 3
    }

def train_dqn(model, episodes=1000):
    """Deep Q-Network学習 (勾配伝播対応)"""
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    print("🚀 量子AI学習開始")
    print(f"パラメータ数: {sum(p.numel() for p in model.parameters())}")
    print(f"戦略: balanced")
    print(f"量子ビット数: 8")
    
    for episode in range(episodes):
        state = torch.randn(1, 36)
        next_state = torch.randn(1, 36)
        
        current_q = model(state)
        next_q = model(next_state)
        
        action = torch.randint(0, 4, (1,))
        reward = torch.randn(1)
        
        target = reward + 0.99 * next_q.max(1)[0].detach()
        current_q_value = current_q.gather(1, action.unsqueeze(1))
        
        loss = criterion(current_q_value.squeeze(), target)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        if episode % 100 == 0:
            print(f"Episode {episode}: Loss={loss.item():.6f}")
            
            # 勾配確認
            total_grad_norm = sum(p.grad.norm().item() if p.grad is not None else 0 
                                for p in model.parameters())
            print(f"勾配ノルム: {total_grad_norm:.6f}")
    
    print("✅ 学習完了")
    return model

if __name__ == "__main__":
    # モデル作成
    model = AutoGeneratedQuantumModel()
    print(f"Model created with {sum(p.numel() for p in model.parameters())} parameters")
    
    # 学習実行
    trained_model = train_dqn(model)
    
    # モデル保存
    timestamp = "2025_9_3 19_41_03"
    model_name = f"quantum_ai_balanced_{timestamp}.pth"
    torch.save(trained_model.state_dict(), model_name)
    print(f"💾 モデル保存: {model_name}")
