#!/usr/bin/env python3
"""
Quantum AI Model Training Script
test19.pyã®é‡å­å›è·¯è¨­å®šã‚’ä½¿ç”¨ã—ã¦ã‚¬ã‚¤ã‚¹ã‚¿ãƒ¼é‡å­AIã‚’å­¦ç¿’
"""

import sys
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
from pathlib import Path
from datetime import datetime
import json

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from qugeister.core.game_engine import GeisterEngine
from qugeister.quantum.quantum_trainer import FastQuantumNeuralNetwork

class QuantumTrainer:
    """é‡å­CNNãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼"""
    
    def __init__(self, config=None):
        # test19.pyã®è¨­å®šã‚’èª­ã¿è¾¼ã¿ (OpenQASMã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠ½å‡º)
        self.config = config or {
            'qubits': 8,
            'layers': 3,
            'entanglement': 'linear',
            'epochs': 100,
            'batch_size': 32,
            'learning_rate': 0.001
        }
        
        print(f"ğŸ”§ é‡å­CNNè¨­å®š: {self.config['qubits']}qubits, {self.config['layers']}layers, {self.config['entanglement']}")
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.model = FastQuantumNeuralNetwork(
            input_dim=252,
            output_dim=36,
            n_qubits=self.config['qubits'],
            n_layers=self.config['layers'],
            embedding='angle',
            entanglement=self.config['entanglement']
        )
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.config['learning_rate'])
        self.criterion = nn.MSELoss()
        
        # å­¦ç¿’çµ±è¨ˆ
        self.training_stats = {
            'losses': [],
            'accuracies': [],
            'q_values': []
        }
        
    def generate_training_data(self, num_samples=1000):
        """ã‚²ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        print(f"ğŸ® {num_samples}å€‹ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
        
        X, y = [], []
        
        for i in range(num_samples):
            # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚²ãƒ¼ãƒ çŠ¶æ…‹ã‚’ç”Ÿæˆ
            game = GeisterEngine()
            
            # ãƒ©ãƒ³ãƒ€ãƒ ã«æ•°æ‰‹é€²ã‚ã‚‹
            for _ in range(random.randint(0, 20)):
                if game.game_over:
                    break
                legal_moves = game.get_legal_moves(game.current_player)
                if legal_moves:
                    move = random.choice(legal_moves)
                    game.make_move(move[0], move[1])
            
            # ã‚²ãƒ¼ãƒ çŠ¶æ…‹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            state = game.get_game_state('A')
            state_vector = torch.tensor(state.to_vector(), dtype=torch.float32)
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆQå€¤ã‚’ç”Ÿæˆï¼ˆç°¡å˜ãªè©•ä¾¡é–¢æ•°ï¼‰
            target_q = self._evaluate_position(game, 'A')
            
            X.append(state_vector)
            y.append(target_q)
            
            if (i + 1) % 100 == 0:
                print(f"  ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé€²æ—: {i+1}/{num_samples}")
        
        return torch.stack(X), torch.stack(y)
    
    def _evaluate_position(self, game, player):
        """ç°¡å˜ãªä½ç½®è©•ä¾¡é–¢æ•°"""
        # 36æ¬¡å…ƒã®Qå€¤ã‚’ç”Ÿæˆ
        q_values = torch.zeros(36)
        
        # è‡ªåˆ†ã®é§’æ•°ã«åŸºã¥ãåŸºæœ¬è©•ä¾¡
        player_pieces = len(game.player_a_pieces if player == 'A' else game.player_b_pieces)
        enemy_pieces = len(game.player_b_pieces if player == 'A' else game.player_a_pieces)
        
        base_value = (player_pieces - enemy_pieces) * 0.1
        
        # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã‚’è¿½åŠ ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿
        for i in range(36):
            q_values[i] = base_value + random.uniform(-0.3, 0.3)
        
        # è„±å‡ºå¯èƒ½æ€§ã‚’è€ƒæ…®
        if game.can_escape(player):
            q_values[-1] = base_value + 0.5  # æœ€å¾Œã®è¦ç´ ã‚’è„±å‡ºQå€¤ã¨ã—ã¦ä½¿ç”¨
        
        return q_values
    
    def train_epoch(self, X, y, batch_size=32):
        """1ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’"""
        self.model.train()
        total_loss = 0.0
        num_batches = len(X) // batch_size
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        indices = torch.randperm(len(X))
        X_shuffled = X[indices]
        y_shuffled = y[indices]
        
        for i in range(num_batches):
            start_idx = i * batch_size
            end_idx = start_idx + batch_size
            
            batch_X = X_shuffled[start_idx:end_idx]
            batch_y = y_shuffled[start_idx:end_idx]
            
            # é †ä¼æ’­
            self.optimizer.zero_grad()
            predictions = torch.stack([self.model(x) for x in batch_X])
            
            # æå¤±è¨ˆç®—
            loss = self.criterion(predictions, batch_y)
            
            # é€†ä¼æ’­
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / num_batches
    
    def evaluate_model(self, X, y):
        """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""
        self.model.eval()
        with torch.no_grad():
            predictions = torch.stack([self.model(x) for x in X[:100]])  # 100ã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡
            targets = y[:100]
            
            # MSEç²¾åº¦
            mse = nn.MSELoss()(predictions, targets).item()
            
            # ç›¸é–¢ä¿‚æ•°ï¼ˆè¿‘ä¼¼ç²¾åº¦ï¼‰
            pred_flat = predictions.flatten()
            target_flat = targets.flatten()
            correlation = torch.corrcoef(torch.stack([pred_flat, target_flat]))[0, 1].item()
            
            return {
                'mse': mse,
                'correlation': correlation if not torch.isnan(torch.tensor(correlation)) else 0.0
            }
    
    def train(self, epochs=None, save_path="models/quantum_model_test19.pth"):
        """ãƒ¡ã‚¤ãƒ³å­¦ç¿’ãƒ«ãƒ¼ãƒ—"""
        epochs = epochs or self.config['epochs']
        
        print(f"ğŸš€ é‡å­CNNå­¦ç¿’é–‹å§‹: {epochs}ã‚¨ãƒãƒƒã‚¯")
        print(f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {sum(p.numel() for p in self.model.parameters()):,}")
        
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        X_train, y_train = self.generate_training_data(2000)
        X_val, y_val = self.generate_training_data(500)
        
        print(f"ğŸ“ˆ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(X_train)}, æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(X_val)}")
        
        best_loss = float('inf')
        
        for epoch in range(epochs):
            # å­¦ç¿’
            train_loss = self.train_epoch(X_train, y_train, self.config['batch_size'])
            
            # è©•ä¾¡
            if epoch % 10 == 0:
                eval_metrics = self.evaluate_model(X_val, y_val)
                
                print(f"Epoch {epoch:3d}/{epochs}: "
                      f"Loss={train_loss:.4f}, "
                      f"Val_MSE={eval_metrics['mse']:.4f}, "
                      f"Correlation={eval_metrics['correlation']:.3f}")
                
                # çµ±è¨ˆä¿å­˜
                self.training_stats['losses'].append(train_loss)
                self.training_stats['accuracies'].append(eval_metrics['correlation'])
                
                # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜
                if train_loss < best_loss:
                    best_loss = train_loss
                    self.save_model(save_path, epoch, train_loss)
        
        print(f"âœ… å­¦ç¿’å®Œäº†! ãƒ™ã‚¹ãƒˆæå¤±: {best_loss:.4f}")
        return self.training_stats
    
    def save_model(self, path, epoch, loss):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        Path(path).parent.mkdir(parents=True, exist_ok=True)
        
        torch.save({
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'loss': loss,
            'config': self.config,
            'stats': self.training_stats
        }, path)
        
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {path}")
    
    def test_model(self):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ§ª å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ...")
        
        # ãƒ†ã‚¹ãƒˆã‚²ãƒ¼ãƒ ä½œæˆ
        game = GeisterEngine()
        state = game.get_game_state('A')
        state_vector = torch.tensor(state.to_vector(), dtype=torch.float32)
        
        # æ¨è«–å®Ÿè¡Œ
        self.model.eval()
        with torch.no_grad():
            q_values = self.model(state_vector)
            action_q = self.model.get_action_from_qmap(state_vector)
        
        print(f"ğŸ“Š Qå€¤å‡ºåŠ›ç¯„å›²: [{q_values.min():.3f}, {q_values.max():.3f}]")
        print(f"ğŸ¯ è¡Œå‹•Qå€¤: {action_q.tolist()}")
        print(f"âœ… æ¨è«–æˆåŠŸ: {state_vector.shape} â†’ {q_values.shape}")

def parse_test19_config():
    """test19.pyã‹ã‚‰è¨­å®šã‚’è§£æ"""
    try:
        with open('test19.py', 'r') as f:
            content = f.read()
        
        config = {'qubits': 8, 'layers': 3, 'entanglement': 'linear'}
        
        # ã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰è¨­å®šæŠ½å‡º
        for line in content.split('\n'):
            if 'Qubits:' in line:
                config['qubits'] = int(line.split('Qubits:')[1].strip())
            elif 'Layers:' in line:
                config['layers'] = int(line.split('Layers:')[1].strip())
            elif 'Entanglement:' in line:
                config['entanglement'] = line.split('Entanglement:')[1].strip()
        
        return config
    except:
        return {'qubits': 8, 'layers': 3, 'entanglement': 'linear'}

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸŒŒ Quantum Geister AI Training")
    print("=" * 50)
    
    # test19.pyã®è¨­å®šã‚’èª­ã¿è¾¼ã¿
    config = parse_test19_config()
    config.update({
        'epochs': 50,
        'batch_size': 16,
        'learning_rate': 0.001
    })
    
    print(f"ğŸ“‹ å­¦ç¿’è¨­å®š: {config}")
    
    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
    trainer = QuantumTrainer(config)
    
    # å­¦ç¿’å®Ÿè¡Œ
    stats = trainer.train()
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    trainer.test_model()
    
    # çµ±è¨ˆä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    stats_path = f"learning/trained_models/test19_{timestamp}/training_stats.json"
    Path(stats_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(stats_path, 'w') as f:
        json.dump(stats, f, indent=2)
    
    print(f"ğŸ“ˆ å­¦ç¿’çµ±è¨ˆä¿å­˜: {stats_path}")
    print("ğŸ® å­¦ç¿’å®Œäº†!")

if __name__ == "__main__":
    main()