#!/usr/bin/env python3
"""
é«˜é€Ÿé‡å­å›è·¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼
é‡å­å›è·¯ã‚’ä½¿ã„ãªãŒã‚‰å®Ÿç”¨çš„ãªé€Ÿåº¦ã§å­¦ç¿’ã‚’å®Ÿç¾
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pennylane as qml
from collections import deque
import random
import time
from tqdm import tqdm
import pickle
from functools import lru_cache
import hashlib

# ===== é«˜é€ŸåŒ–é‡å­å›è·¯å®Ÿè£… =====
class FastQuantumCircuit:
    """æœ€é©åŒ–ã•ã‚ŒãŸé‡å­å›è·¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self, n_qubits=4, n_layers=1):
        self.n_qubits = n_qubits
        self.n_layers = n_layers
        
        # 1. Lightning.qubitã‚’è©¦ã¿ã€ãªã‘ã‚Œã°default.qubitã‚’ä½¿ç”¨
        try:
            self.dev = qml.device('lightning.qubit', wires=n_qubits)
            print("âœ… Lightning.qubitä½¿ç”¨ï¼ˆé«˜é€Ÿï¼‰")
        except:
            self.dev = qml.device('default.qubit', wires=n_qubits)
            print("âš ï¸ Default.qubitä½¿ç”¨ï¼ˆæ¨™æº–é€Ÿåº¦ï¼‰")
        
        # 2. é‡å­å›è·¯ã‚’JITæœ€é©åŒ–
        self.quantum_circuit = self._build_optimized_circuit()
        
        # 3. è¨ˆç®—çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆLRU: Least Recently Usedï¼‰
        self.cache_size = 10000
        self._cache_enabled = True
        
        # 4. ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆäº‹å‰è¨ˆç®—ï¼‰
        self.lookup_table = {}
        self.precompute_common_patterns()
    
    def _build_optimized_circuit(self):
        """æœ€é©åŒ–ã•ã‚ŒãŸé‡å­å›è·¯ã®æ§‹ç¯‰"""
        
        @qml.qnode(self.dev, interface='torch', diff_method='backprop')
        def circuit(inputs, weights):
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆé«˜é€Ÿï¼‰
            for i in range(self.n_qubits):
                qml.RY(inputs[i], wires=i)
            
            # æœ€å°é™ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°
            for l in range(self.n_layers):
                # åŠ¹ç‡çš„ãªã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆ
                for i in range(0, self.n_qubits - 1, 2):
                    qml.CNOT(wires=[i, i + 1])
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚²ãƒ¼ãƒˆ
                for i in range(self.n_qubits):
                    qml.RY(weights[l, i, 0], wires=i)
                    qml.RZ(weights[l, i, 1], wires=i)
            
            # æ¸¬å®š
            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]
        
        return circuit
    
    def precompute_common_patterns(self):
        """ã‚ˆãä½¿ã‚ã‚Œã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’äº‹å‰è¨ˆç®—"""
        print("ğŸ”„ é‡å­å›è·¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’äº‹å‰è¨ˆç®—ä¸­...")
        
        # ä»£è¡¨çš„ãªå…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’äº‹å‰è¨ˆç®—
        common_patterns = [
            torch.zeros(self.n_qubits),  # ã‚¼ãƒ­çŠ¶æ…‹
            torch.ones(self.n_qubits) * np.pi / 2,  # å‡ç­‰é‡ã­åˆã‚ã›
            torch.tensor([np.pi * i / self.n_qubits for i in range(self.n_qubits)]),  # ç·šå½¢
        ]
        
        weights = torch.randn(self.n_layers, self.n_qubits, 2) * 0.1
        
        for pattern in common_patterns:
            key = self._hash_input(pattern)
            self.lookup_table[key] = self.quantum_circuit(pattern, weights)
        
        print(f"âœ… {len(self.lookup_table)}å€‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’äº‹å‰è¨ˆç®—å®Œäº†")
    
    @lru_cache(maxsize=10000)
    def _hash_input(self, tensor_input):
        """å…¥åŠ›ã‚’ãƒãƒƒã‚·ãƒ¥åŒ–ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        if isinstance(tensor_input, torch.Tensor):
            array = tensor_input.detach().numpy()
        else:
            array = np.array(tensor_input)
        
        # ç²¾åº¦ã‚’ä¸‹ã’ã¦ãƒãƒƒã‚·ãƒ¥ï¼ˆè¿‘ä¼¼å€¤ã§ã‚‚ãƒ’ãƒƒãƒˆã™ã‚‹ã‚ˆã†ã«ï¼‰
        rounded = np.round(array, decimals=3)
        return hashlib.md5(rounded.tobytes()).hexdigest()
    
    def forward(self, inputs, weights):
        """é«˜é€ŸåŒ–ã•ã‚ŒãŸé †ä¼æ’­"""
        # 1. ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        input_hash = self._hash_input(inputs)
        if input_hash in self.lookup_table:
            return self.lookup_table[input_hash]
        
        # 2. é€šå¸¸ã®é‡å­å›è·¯å®Ÿè¡Œ
        result = self.quantum_circuit(inputs, weights)
        
        # 3. çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        if len(self.lookup_table) < self.cache_size:
            self.lookup_table[input_hash] = result
        
        return result

# ===== ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰é‡å­-å¤å…¸ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ =====
class FastQuantumNeuralNetwork(nn.Module):
    """é«˜é€ŸåŒ–ã•ã‚ŒãŸé‡å­ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"""
    
    def __init__(self, input_dim=252, output_dim=36, n_qubits=4):  # Changed to 36 for Q-value map
        super().__init__()
        self.n_qubits = n_qubits
        self.output_dim = output_dim
        
        # 1. å‰å‡¦ç†å±¤ï¼ˆæ¬¡å…ƒå‰Šæ¸›ï¼‰
        self.preprocessor = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, n_qubits),
            nn.Tanh()  # é‡å­å›è·¯ã®å…¥åŠ›ç¯„å›²ã«æ­£è¦åŒ–
        )
        
        # 2. é‡å­å›è·¯å±¤ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
        self.quantum_layer = FastQuantumCircuit(n_qubits=n_qubits, n_layers=1)
        
        # 3. å¾Œå‡¦ç†å±¤ï¼ˆQå€¤ãƒãƒƒãƒ—ç”¨ã«æ‹¡å¼µï¼‰
        self.postprocessor = nn.Sequential(
            nn.Linear(n_qubits, 32),  # Increased hidden size for 36 outputs
            nn.ReLU(),
            nn.Linear(32, output_dim),  # 36 outputs for 6x6 Q-value map
            nn.Tanh()  # Normalize Q-values to [-1, 1] range
        )
        
        # 4. é‡å­å›è·¯ã®é‡ã¿ï¼ˆå­¦ç¿’å¯èƒ½ï¼‰
        self.quantum_weights = nn.Parameter(torch.randn(1, n_qubits, 2) * 0.1)
    
    def forward(self, x):
        # ãƒãƒƒãƒå‡¦ç†ã®æœ€é©åŒ–
        batch_size = x.shape[0] if x.dim() > 1 else 1
        if x.dim() == 1:
            x = x.unsqueeze(0)
        
        # 1. å‰å‡¦ç†ã§æ¬¡å…ƒå‰Šæ¸›
        compressed = self.preprocessor(x)
        
        # 2. é‡å­å›è·¯å‡¦ç†ï¼ˆãƒãƒƒãƒæœ€é©åŒ–ï¼‰
        quantum_outputs = []
        for i in range(batch_size):
            # å„ã‚µãƒ³ãƒ—ãƒ«ã‚’é‡å­å›è·¯ã«é€šã™
            quantum_input = compressed[i] * np.pi  # [-Ï€, Ï€]ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            quantum_output = self.quantum_layer.forward(
                quantum_input, 
                self.quantum_weights
            )
            quantum_outputs.append(quantum_output)
        
        # 3. ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        if batch_size > 1:
            quantum_features = torch.stack([torch.tensor(out, dtype=torch.float32) for out in quantum_outputs])
        else:
            quantum_features = torch.tensor(quantum_outputs[0], dtype=torch.float32).unsqueeze(0)
        
        # 4. å¾Œå‡¦ç†
        output = self.postprocessor(quantum_features)
        
        return output.squeeze(0) if batch_size == 1 else output
    
    def get_qvalue_map(self, x):
        """36æ¬¡å…ƒå‡ºåŠ›ã‚’6x6ã®Qå€¤ãƒãƒƒãƒ—ã«å¤‰æ›"""
        output = self.forward(x)
        if output.dim() == 1:
            # Single sample: reshape to 6x6
            return output.reshape(6, 6)
        else:
            # Batch: reshape each sample to 6x6
            return output.reshape(-1, 6, 6)
    
    def get_action_from_qmap(self, x):
        """Qå€¤ãƒãƒƒãƒ—ã‹ã‚‰æœ€é©è¡Œå‹•ã‚’é¸æŠï¼ˆå¾“æ¥ã®5è¡Œå‹•ã‚·ã‚¹ãƒ†ãƒ ç”¨ï¼‰"""
        qvalue_map = self.get_qvalue_map(x)
        if qvalue_map.dim() == 2:  # Single sample
            # 6x6ãƒãƒƒãƒ—ã‹ã‚‰ä»£è¡¨çš„ãª5ã¤ã®é ˜åŸŸã®æœ€å¤§å€¤ã‚’å–å¾—
            regions = {
                0: qvalue_map[0:2, 0:3].max(),  # å·¦ä¸Šé ˜åŸŸ
                1: qvalue_map[0:2, 3:6].max(),  # å³ä¸Šé ˜åŸŸ
                2: qvalue_map[2:4, 1:5].max(),  # ä¸­å¤®é ˜åŸŸ
                3: qvalue_map[4:6, 0:3].max(),  # å·¦ä¸‹é ˜åŸŸ
                4: qvalue_map[4:6, 3:6].max(),  # å³ä¸‹é ˜åŸŸ
            }
            # 5ã¤ã®è¡Œå‹•ã«å¯¾å¿œã™ã‚‹Qå€¤ã‚’è¿”ã™
            return torch.tensor([regions[i] for i in range(5)])
        else:  # Batch
            batch_size = qvalue_map.shape[0]
            batch_actions = []
            for i in range(batch_size):
                single_map = qvalue_map[i]
                regions = {
                    0: single_map[0:2, 0:3].max(),
                    1: single_map[0:2, 3:6].max(),
                    2: single_map[2:4, 1:5].max(),
                    3: single_map[4:6, 0:3].max(),
                    4: single_map[4:6, 3:6].max(),
                }
                batch_actions.append([regions[i] for i in range(5)])
            return torch.tensor(batch_actions)

# ===== é«˜é€Ÿå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  =====
class FastQuantumTrainer:
    """é«˜é€Ÿé‡å­å›è·¯å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, model, lr=0.001):
        self.model = model
        self.optimizer = optim.Adam(model.parameters(), lr=lr)
        self.replay_buffer = deque(maxlen=1000)
        
        # å­¦ç¿’çµ±è¨ˆ
        self.losses = []
        self.rewards = []
        
    def train_step(self, batch_size=8):
        """åŠ¹ç‡çš„ãªãƒãƒƒãƒå­¦ç¿’"""
        if len(self.replay_buffer) < batch_size:
            return None
        
        # ãƒŸãƒ‹ãƒãƒƒãƒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        batch = random.sample(self.replay_buffer, batch_size)
        states, actions, rewards, next_states, dones = zip(*batch)
        
        # ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›ï¼ˆåŠ¹ç‡åŒ–ï¼‰
        states = torch.cat(states)
        actions = torch.tensor(actions, dtype=torch.long)
        rewards = torch.tensor(rewards, dtype=torch.float32)
        next_states = torch.cat(next_states)
        dones = torch.tensor(dones, dtype=torch.float32)
        
        # Qå€¤è¨ˆç®—ï¼ˆ36æ¬¡å…ƒå‡ºåŠ›ã‹ã‚‰5è¡Œå‹•ç”¨Qå€¤ã‚’æŠ½å‡ºï¼‰
        current_q_actions = self.model.get_action_from_qmap(states)
        current_q = current_q_actions.gather(1, actions.unsqueeze(1)).squeeze()
        
        with torch.no_grad():
            next_q_actions = self.model.get_action_from_qmap(next_states)
            next_q = next_q_actions.max(1)[0]
            target_q = rewards + 0.99 * next_q * (1 - dones)
        
        # æå¤±è¨ˆç®—
        loss = nn.MSELoss()(current_q, target_q)
        
        # æœ€é©åŒ–
        self.optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
        self.optimizer.step()
        
        self.losses.append(loss.item())
        return loss.item()

# ===== ãƒ¡ã‚¤ãƒ³å­¦ç¿’ãƒ«ãƒ¼ãƒ— =====
def train_fast_quantum(episodes=1000, n_qubits=4):
    """é«˜é€Ÿé‡å­å›è·¯å­¦ç¿’ã®å®Ÿè¡Œ"""
    
    print("=" * 60)
    print("ğŸš€ é«˜é€Ÿé‡å­å›è·¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å­¦ç¿’")
    print("=" * 60)
    print(f"é‡å­ãƒ“ãƒƒãƒˆæ•°: {n_qubits}")
    print(f"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {episodes}")
    print("=" * 60)
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
    model = FastQuantumNeuralNetwork(n_qubits=n_qubits)
    trainer = FastQuantumTrainer(model)
    
    # é€²æ—è¡¨ç¤º
    episode_rewards = []
    start_time = time.time()
    
    with tqdm(total=episodes, desc="é‡å­å›è·¯å­¦ç¿’") as pbar:
        for episode in range(episodes):
            # ç’°å¢ƒãƒªã‚»ãƒƒãƒˆï¼ˆç°¡ç•¥åŒ–ï¼‰
            state = torch.randn(1, 252)
            episode_reward = 0
            done = False
            steps = 0
            
            while not done and steps < 100:
                # è¡Œå‹•é¸æŠï¼ˆÎµ-greedyï¼‰
                epsilon = max(0.01, 0.1 * (0.995 ** episode))
                if random.random() < epsilon:
                    action = random.randrange(5)
                else:
                    with torch.no_grad():
                        q_values = model.get_action_from_qmap(state)
                        action = q_values.argmax().item()
                
                # ç’°å¢ƒã‚¹ãƒ†ãƒƒãƒ—ï¼ˆç°¡ç•¥åŒ–ï¼‰
                next_state = torch.randn(1, 252)
                reward = random.uniform(-1, 1)
                done = random.random() < 0.1
                
                # çµŒé¨“ã‚’ä¿å­˜
                trainer.replay_buffer.append(
                    (state, action, reward, next_state, done)
                )
                
                # å­¦ç¿’
                loss = trainer.train_step()
                
                # æ›´æ–°
                state = next_state
                episode_reward += reward
                steps += 1
            
            episode_rewards.append(episode_reward)
            
            # é€²æ—æ›´æ–°
            if (episode + 1) % 10 == 0:
                avg_reward = np.mean(episode_rewards[-10:])
                elapsed = time.time() - start_time
                speed = (episode + 1) / elapsed
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
                cache_size = len(model.quantum_layer.lookup_table)
                
                pbar.set_postfix({
                    'Avg Reward': f'{avg_reward:.2f}',
                    'Speed': f'{speed:.1f} eps/s',
                    'Cache': f'{cache_size}/{model.quantum_layer.cache_size}',
                    'Îµ': f'{epsilon:.3f}'
                })
            
            pbar.update(1)
    
    # çµæœè¡¨ç¤º
    total_time = time.time() - start_time
    print(f"\nâœ… å­¦ç¿’å®Œäº†ï¼")
    print(f"ç·æ™‚é–“: {total_time:.1f}ç§’")
    print(f"é€Ÿåº¦: {episodes/total_time:.1f} ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰/ç§’")
    print(f"æœ€çµ‚å ±é…¬: {np.mean(episode_rewards[-100:]):.2f}")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    torch.save({
        'model_state_dict': model.state_dict(),
        'quantum_cache': model.quantum_layer.lookup_table,
        'rewards': episode_rewards
    }, 'fast_quantum_model.pth')
    
    print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ 'fast_quantum_model.pth' ã¨ã—ã¦ä¿å­˜")
    
    return model, episode_rewards

# ===== ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ =====
def benchmark_quantum_speedup():
    """é‡å­å›è·¯ã®é«˜é€ŸåŒ–åŠ¹æœã‚’æ¸¬å®š"""
    
    print("\n" + "=" * 60)
    print("ğŸ“Š é‡å­å›è·¯é«˜é€ŸåŒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    print("=" * 60)
    
    # é€šå¸¸ã®é‡å­å›è·¯
    print("\n1. é€šå¸¸ã®é‡å­å›è·¯ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—ï¼‰:")
    circuit_nocache = FastQuantumCircuit(n_qubits=4)
    circuit_nocache._cache_enabled = False
    
    start = time.time()
    for _ in range(100):
        inputs = torch.randn(4) * np.pi
        weights = torch.randn(1, 4, 2) * 0.1
        _ = circuit_nocache.forward(inputs, weights)
    normal_time = time.time() - start
    print(f"   100å›å®Ÿè¡Œ: {normal_time:.2f}ç§’")
    
    # é«˜é€ŸåŒ–é‡å­å›è·¯
    print("\n2. é«˜é€ŸåŒ–é‡å­å›è·¯ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰:")
    circuit_fast = FastQuantumCircuit(n_qubits=4)
    
    start = time.time()
    for i in range(100):
        # ä¸€éƒ¨ã¯åŒã˜å…¥åŠ›ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼‰
        if i % 3 == 0:
            inputs = torch.zeros(4)
        else:
            inputs = torch.randn(4) * np.pi
        weights = torch.randn(1, 4, 2) * 0.1
        _ = circuit_fast.forward(inputs, weights)
    fast_time = time.time() - start
    print(f"   100å›å®Ÿè¡Œ: {fast_time:.2f}ç§’")
    print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {len(circuit_fast.lookup_table)}/100")
    
    print(f"\nâš¡ é«˜é€ŸåŒ–å€ç‡: {normal_time/fast_time:.1f}å€")
    
    # ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    print("\n3. ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆ1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰:")
    model = FastQuantumNeuralNetwork(n_qubits=4)
    
    start = time.time()
    for _ in range(10):
        state = torch.randn(1, 252)
        _ = model(state)
    model_time = time.time() - start
    print(f"   10ã‚¹ãƒ†ãƒƒãƒ—: {model_time:.2f}ç§’")
    print(f"   æ¨å®š1000ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {model_time * 100:.0f}ç§’")

if __name__ == "__main__":
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    benchmark_quantum_speedup()
    
    # å­¦ç¿’å®Ÿè¡Œ
    print("\né‡å­å›è·¯å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ")
    print("1. ãƒ‡ãƒ¢ï¼ˆ100ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰")
    print("2. æ¨™æº–ï¼ˆ1000ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰")
    print("3. ãƒ•ãƒ«ï¼ˆ10000ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼‰")
    
    import sys
    if len(sys.argv) > 1:
        choice = sys.argv[1]
        if choice == "1":
            model, rewards = train_fast_quantum(100, n_qubits=4)
        elif choice == "2":
            model, rewards = train_fast_quantum(1000, n_qubits=4)
        elif choice == "3":
            model, rewards = train_fast_quantum(10000, n_qubits=4)
    else:
        print("\nãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ")
        model, rewards = train_fast_quantum(100, n_qubits=4)