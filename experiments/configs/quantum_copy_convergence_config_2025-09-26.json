{
  "metadata": {
    "generated_by": "Claude Code - Copy Version Convergence Optimizer",
    "generated_at": "2025-09-26T00:00:00.000Z",
    "version": "1.5.0",
    "experiment_type": "copy_version_convergence_enhanced",
    "base_config": "quantum_cqcnn_config_2025-09-24.json",
    "improvements": [
      "Slower epsilon decay for better exploration",
      "Larger replay buffer for experience diversity",
      "Balanced learning rates",
      "Enhanced quantum circuit depth",
      "Stability-focused hyperparameters",
      "Maintained 252D dimensional consistency"
    ]
  },
  "learning_config": {
    "method": "reinforcement",
    "algorithm": "stable_spatial_36d",
    "timestamp": "2025-09-26T00:00:00.000Z",
    "strategy": "stable_convergence"
  },
  "module_config": {
    "placement": {
      "type": "custom",
      "description": "標準配置：バランス型の初期配置\n- 前列と後列にバランス良く駒を配置\n- 善玉と悪玉を混在させて相手の推測を困難にする\n- 脱出と攻撃の両方に対応可能な柔軟な配置",
      "player_a_bottom": true,
      "player_b_top": true,
      "my_pieces_config": [
        [0, 1, -1, -1, 1, 0],
        [0, 1, -1, -1, 1, 0]
      ],
      "escape_positions": {
        "player_a": [[0, 0], [0, 5]],
        "player_b": [[5, 0], [5, 5]]
      }
    },
    "quantum": {
      "description": "Enhanced Classical-Quantum CNN (252D Compatible)\n- 前処理CNN: 252次元の盤面状態を量子ビット数に圧縮\n- 量子回路: 改良されたパラメータ化量子回路（2層）\n- 後処理CNN: 量子特徴を最終出力に変換\n- 次元の一貫性を保持",
      "n_qubits": 4,
      "n_layers": 2,
      "embedding_type": "angle",
      "entanglement": "full",
      "total_params": 24,
      "state_channels": 7,
      "state_dimension": 252,
      "parameter_init": "xavier_uniform",
      "noise_resilience": true
    },
    "reward": {
      "description": "改良型バランス報酬設計\n• 相手の善玉を捕獲: +10ポイント\n• 相手の悪玉を捕獲: -3ポイント (軽減)\n• 脱出成功: +50ポイント\n• 善玉が取られる: -15ポイント (軽減)\n• 悪玉を取らせる: +8ポイント\n• 位置的報酬の最適化",
      "strategy": "balanced_stable",
      "capture_good_reward": 10,
      "capture_bad_penalty": -3,
      "escape_reward": 50,
      "captured_good_penalty": -15,
      "captured_bad_reward": 8,
      "position_rewards": {
        "advance_toward_escape": 1.5,
        "center_control": 0.8,
        "opponent_territory": 2.5,
        "defensive_positioning": 1.0
      }
    },
    "qmap": {
      "description": "36次元空間Q値マッピング（安定版）\n• 252次元状態から36次元行動への変換\n• 有効手のみの学習で効率化\n• 次元の一貫性維持",
      "method": "stable_spatial_36d",
      "state_dim": 252,
      "action_dim": 36,
      "selected_channels": 7,
      "legal_moves_only": true,
      "action_weighting": "balanced",
      "exploration_bonus": 0.05
    },
    "action_selection": {
      "description": "安定化ε-greedy戦略\n• 収束を重視したε減衰設計\n• 十分な探索期間の確保\n• バランスの取れた探索/活用",
      "strategy": "stable_epsilon",
      "epsilon_player_1": 0.5,
      "epsilon_player_2": 0.5,
      "temperature": null,
      "adaptive_decay": false
    }
  },
  "hyperparameters": {
    "learning_rate": 0.0008,
    "batch_size": 128,
    "epochs": 50000,
    "validation_split": 0.15,
    "optimizer": "adam",
    "scheduler": "cosine_annealing",
    "scheduler_params": {
      "T_max": 8000,
      "eta_min": 0.00001
    },
    "dropout_rate": 0.25,
    "l2_regularization": 0.0003,
    "gradient_clipping": 1.0,
    "epsilon": 0.5,
    "epsilon_decay": 0.9997,
    "epsilon_min": 0.05,
    "gamma": 0.97,
    "replay_buffer_size": 3000,
    "target_update_freq": 150,
    "polyak_tau": 0.005,
    "prioritized_replay": true,
    "priority_alpha": 0.6,
    "priority_beta": 0.4,
    "double_dqn": true,
    "training_frequency": 8
  },
  "architecture": {
    "type": "Stable_CQCNN_252D",
    "frontend_cnn": {
      "input_channels": 7,
      "layers": [
        {
          "type": "linear",
          "in_features": 252,
          "out_features": 128
        },
        {
          "type": "batch_norm",
          "num_features": 128
        },
        {
          "type": "relu"
        },
        {
          "type": "dropout",
          "p": 0.25
        },
        {
          "type": "linear",
          "in_features": 128,
          "out_features": 64
        },
        {
          "type": "batch_norm",
          "num_features": 64
        },
        {
          "type": "relu"
        },
        {
          "type": "dropout",
          "p": 0.2
        },
        {
          "type": "linear",
          "in_features": 64,
          "out_features": 32
        },
        {
          "type": "batch_norm",
          "num_features": 32
        },
        {
          "type": "relu"
        },
        {
          "type": "dropout",
          "p": 0.15
        },
        {
          "type": "linear",
          "in_features": 32,
          "out_features": 4
        },
        {
          "type": "tanh"
        }
      ]
    },
    "quantum_section": {
      "n_qubits": 4,
      "n_layers": 2,
      "embedding_type": "angle",
      "entanglement": "full",
      "device": "lightning.qubit",
      "parameter_init": "xavier_uniform",
      "rotation_gates": ["RY", "RZ"],
      "entangling_gates": ["CNOT"],
      "measurement": "expectation_z",
      "circuit_depth": 6
    },
    "backend_cnn": {
      "layers": [
        {
          "type": "linear",
          "in_features": 4,
          "out_features": 64
        },
        {
          "type": "batch_norm",
          "num_features": 64
        },
        {
          "type": "relu"
        },
        {
          "type": "dropout",
          "p": 0.25
        },
        {
          "type": "linear",
          "in_features": 64,
          "out_features": 128
        },
        {
          "type": "batch_norm",
          "num_features": 128
        },
        {
          "type": "relu"
        },
        {
          "type": "dropout",
          "p": 0.2
        },
        {
          "type": "linear",
          "in_features": 128,
          "out_features": 96
        },
        {
          "type": "batch_norm",
          "num_features": 96
        },
        {
          "type": "relu"
        },
        {
          "type": "dropout",
          "p": 0.15
        },
        {
          "type": "linear",
          "in_features": 96,
          "out_features": 64
        },
        {
          "type": "batch_norm",
          "num_features": 64
        },
        {
          "type": "relu"
        },
        {
          "type": "dropout",
          "p": 0.1
        },
        {
          "type": "linear",
          "in_features": 64,
          "out_features": 36
        }
      ]
    }
  },
  "convergence": {
    "balance_threshold": 0.95,
    "patience": 100,
    "min_games": 1000,
    "stability_check": true,
    "early_stopping": {
      "enabled": true,
      "monitor": "balance",
      "patience": 200,
      "min_delta": 0.001
    },
    "checkpointing": {
      "enabled": true,
      "frequency": 500,
      "save_best": true,
      "metric": "balance_score"
    }
  },
  "training_schedule": {
    "warmup_episodes": 500,
    "phase_1": {
      "episodes": "0-3000",
      "focus": "exploration",
      "learning_rate_multiplier": 1.0,
      "epsilon_multiplier": 1.0
    },
    "phase_2": {
      "episodes": "3001-15000",
      "focus": "balanced_learning",
      "learning_rate_multiplier": 0.8,
      "epsilon_multiplier": 0.8
    },
    "phase_3": {
      "episodes": "15001-50000",
      "focus": "convergence",
      "learning_rate_multiplier": 0.6,
      "epsilon_multiplier": 0.6
    }
  },
  "experimental_features": {
    "curriculum_learning": false,
    "adaptive_buffer_size": false,
    "dynamic_reward_scaling": false,
    "multi_step_returns": false,
    "noisy_networks": false,
    "distributional_rl": false
  },
  "logging": {
    "tensorboard": true,
    "wandb": false,
    "detailed_metrics": true,
    "save_frequency": 100,
    "plot_frequency": 500,
    "convergence_tracking": true
  }
}