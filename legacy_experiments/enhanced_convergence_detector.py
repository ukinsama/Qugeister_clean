#!/usr/bin/env python3
"""
å¼·åŒ–ã•ã‚ŒãŸåæŸæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
Lossæ”¹å–„ã‚’å«ã‚€åŒ…æ‹¬çš„ãªåœæ­¢æ¡ä»¶ã‚’å®Ÿè£…
"""

import numpy as np
from collections import deque
import torch

class EnhancedConvergenceDetector:
    """Lossæ”¹å–„ã‚’å«ã‚€åŒ…æ‹¬çš„åæŸæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self,
                 balance_threshold=0.95,
                 patience=50,
                 min_games=1000,
                 loss_patience=20,
                 loss_improvement_threshold=0.001,
                 min_loss_samples=100):

        # BalanceåæŸæ¡ä»¶
        self.balance_threshold = balance_threshold
        self.balance_patience = patience
        self.min_games = min_games
        self.consecutive_balance_good = 0
        self.best_balance = 0.0

        # Lossæ”¹å–„æ¡ä»¶
        self.loss_patience = loss_patience
        self.loss_improvement_threshold = loss_improvement_threshold
        self.min_loss_samples = min_loss_samples
        self.loss_history_p1 = deque(maxlen=200)
        self.loss_history_p2 = deque(maxlen=200)
        self.best_loss_p1 = float('inf')
        self.best_loss_p2 = float('inf')
        self.loss_plateau_count = 0

        # ç·åˆåˆ¤å®š
        self.convergence_history = []
        self.early_stopping_triggered = False
        self.stopping_reason = None

        print(f"EnhancedåæŸæ¤œå‡ºå™¨:")
        print(f"  Balance: é–¾å€¤={balance_threshold}, patience={patience}")
        print(f"  Loss: patience={loss_patience}, improvement_threshold={loss_improvement_threshold}")
        print(f"  æœ€å°ã‚²ãƒ¼ãƒ æ•°: {min_games}")

    def update_losses(self, losses_p1, losses_p2):
        """Losså±¥æ­´ã‚’æ›´æ–°"""
        if losses_p1:
            recent_loss_p1 = np.mean(losses_p1[-10:]) if len(losses_p1) >= 10 else losses_p1[-1]
            self.loss_history_p1.append(recent_loss_p1)
            self.best_loss_p1 = min(self.best_loss_p1, recent_loss_p1)

        if losses_p2:
            recent_loss_p2 = np.mean(losses_p2[-10:]) if len(losses_p2) >= 10 else losses_p2[-1]
            self.loss_history_p2.append(recent_loss_p2)
            self.best_loss_p2 = min(self.best_loss_p2, recent_loss_p2)

    def check_loss_improvement(self):
        """Lossæ”¹å–„çŠ¶æ³ã‚’åˆ¤å®š"""
        if len(self.loss_history_p1) < self.min_loss_samples:
            return True, {'status': 'insufficient_loss_data'}

        # ç›´è¿‘ã®Losså¹³å‡
        recent_window = 50
        current_loss_p1 = np.mean(list(self.loss_history_p1)[-recent_window:])
        current_loss_p2 = np.mean(list(self.loss_history_p2)[-recent_window:])

        # ãƒ™ã‚¹ãƒˆã‹ã‚‰ã®å·®
        loss_diff_p1 = current_loss_p1 - self.best_loss_p1
        loss_diff_p2 = current_loss_p2 - self.best_loss_p2

        # æ”¹å–„åˆ¤å®š
        p1_improving = loss_diff_p1 <= self.loss_improvement_threshold
        p2_improving = loss_diff_p2 <= self.loss_improvement_threshold

        # Lossåœæ»ã‚«ã‚¦ãƒ³ãƒˆ
        if not p1_improving or not p2_improving:
            self.loss_plateau_count += 1
        else:
            self.loss_plateau_count = 0

        # Lossç™ºæ•£ãƒã‚§ãƒƒã‚¯
        loss_diverging = (loss_diff_p1 > 0.1 or loss_diff_p2 > 0.1)

        metrics = {
            'current_loss_p1': current_loss_p1,
            'current_loss_p2': current_loss_p2,
            'best_loss_p1': self.best_loss_p1,
            'best_loss_p2': self.best_loss_p2,
            'loss_diff_p1': loss_diff_p1,
            'loss_diff_p2': loss_diff_p2,
            'p1_improving': p1_improving,
            'p2_improving': p2_improving,
            'plateau_count': self.loss_plateau_count,
            'loss_diverging': loss_diverging
        }

        # Lossåœæ­¢æ¡ä»¶
        loss_early_stop = self.loss_plateau_count >= self.loss_patience

        if loss_early_stop:
            metrics['status'] = 'loss_plateau_reached'
        elif loss_diverging:
            metrics['status'] = 'loss_diverging'
        elif p1_improving and p2_improving:
            metrics['status'] = 'loss_improving'
        else:
            metrics['status'] = 'loss_mixed'

        return not loss_early_stop and not loss_diverging, metrics

    def check_balance_convergence(self, game_results):
        """BalanceåæŸã‚’åˆ¤å®š"""
        if len(game_results) < self.min_games:
            return False, 0.0, {'reason': 'insufficient_games', 'games': len(game_results)}

        # æœ€è¿‘ã®çµæœã‚’åˆ†æ
        recent_games = game_results[-500:]

        wins_1 = sum(1 for r in recent_games if r.get('winner') == 1)
        wins_2 = sum(1 for r in recent_games if r.get('winner') == 2)
        draws = sum(1 for r in recent_games if r.get('winner') is None)

        total_games = len(recent_games)
        decisive_games = wins_1 + wins_2

        # ãƒãƒ©ãƒ³ã‚¹è¨ˆç®—
        if decisive_games > 0:
            balance = min(wins_1, wins_2) / max(wins_1, wins_2)
            win_rate_1 = wins_1 / total_games
            win_rate_2 = wins_2 / total_games
            draw_rate = draws / total_games
        else:
            balance = 1.0
            win_rate_1 = win_rate_2 = 0.0
            draw_rate = 1.0

        # åæŸåˆ¤å®š
        is_balanced = balance >= self.balance_threshold
        has_active_games = decisive_games >= 50

        metrics = {
            'balance': balance,
            'win_rate_1': win_rate_1,
            'win_rate_2': win_rate_2,
            'draw_rate': draw_rate,
            'decisive_games': decisive_games,
            'total_games': total_games,
            'is_balanced': is_balanced,
            'has_active_games': has_active_games
        }

        # é€£ç¶šã‚«ã‚¦ãƒ³ãƒˆ
        if is_balanced and has_active_games:
            self.consecutive_balance_good += 1
            metrics['status'] = 'balance_converging'
        else:
            self.consecutive_balance_good = 0
            if not is_balanced:
                metrics['status'] = 'balance_unbalanced'
            elif not has_active_games:
                metrics['status'] = 'too_many_draws'

        metrics['consecutive_good'] = self.consecutive_balance_good
        self.best_balance = max(self.best_balance, balance)
        metrics['best_balance'] = self.best_balance

        # BalanceåæŸåˆ¤å®š
        balance_converged = self.consecutive_balance_good >= self.balance_patience

        return balance_converged, balance, metrics

    def comprehensive_convergence_check(self, game_results, losses_p1, losses_p2, episode):
        """åŒ…æ‹¬çš„åæŸåˆ¤å®šï¼ˆBalance + Lossï¼‰"""

        # Losså±¥æ­´æ›´æ–°
        self.update_losses(losses_p1, losses_p2)

        # BalanceåæŸãƒã‚§ãƒƒã‚¯
        balance_converged, balance, balance_metrics = self.check_balance_convergence(game_results)

        # Lossæ”¹å–„ãƒã‚§ãƒƒã‚¯
        loss_ok, loss_metrics = self.check_loss_improvement()

        # ç·åˆåˆ¤å®š
        comprehensive_metrics = {
            'episode': episode,
            'balance_converged': balance_converged,
            'loss_improving': loss_ok,
            'balance_metrics': balance_metrics,
            'loss_metrics': loss_metrics
        }

        # åœæ­¢æ¡ä»¶åˆ¤å®š
        if balance_converged and loss_ok:
            # ç†æƒ³çš„ãªåæŸ: Balanceé”æˆ + Lossæ”¹å–„
            converged = True
            self.stopping_reason = 'comprehensive_convergence'
            comprehensive_metrics['convergence_type'] = 'optimal'

        elif balance_converged and not loss_ok:
            # Balanceé”æˆã ãŒLossåœæ»
            if loss_metrics.get('loss_diverging', False):
                # Lossç™ºæ•£: æ—©æœŸåœæ­¢
                converged = True
                self.stopping_reason = 'loss_divergence_with_balance'
                comprehensive_metrics['convergence_type'] = 'early_stop_divergence'
            else:
                # Lossåœæ»: ç¶™ç¶šåˆ¤æ–­
                converged = loss_metrics.get('plateau_count', 0) >= self.loss_patience
                self.stopping_reason = 'loss_plateau_with_balance' if converged else None
                comprehensive_metrics['convergence_type'] = 'plateau_stop' if converged else 'monitoring'

        elif not balance_converged and not loss_ok:
            # Balanceæœªé”æˆ + Losså•é¡Œ
            if loss_metrics.get('loss_diverging', False):
                # Lossç™ºæ•£: æ—©æœŸåœæ­¢
                converged = True
                self.stopping_reason = 'loss_divergence_no_balance'
                comprehensive_metrics['convergence_type'] = 'early_stop_divergence'
            else:
                # ä¸¡æ–¹ã¨ã‚‚æ”¹å–„ä½™åœ°ã‚ã‚Š: ç¶™ç¶š
                converged = False
                comprehensive_metrics['convergence_type'] = 'training_ongoing'

        else:
            # Balanceæœªé”æˆã ãŒLossæ”¹å–„: ç¶™ç¶š
            converged = False
            comprehensive_metrics['convergence_type'] = 'loss_improving_continue'

        # å±¥æ­´è¨˜éŒ²
        self.convergence_history.append(comprehensive_metrics.copy())

        return converged, comprehensive_metrics

    def get_convergence_report(self):
        """åæŸãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.convergence_history:
            return "åæŸãƒ‡ãƒ¼ã‚¿ãªã—"

        latest = self.convergence_history[-1]

        report = f"""
=== Enhanced Convergence Report ===
åœæ­¢ç†ç”±: {self.stopping_reason or 'ç¶™ç¶šä¸­'}
åæŸã‚¿ã‚¤ãƒ—: {latest['convergence_type']}

Balance Status:
  - ç¾åœ¨Balance: {latest['balance_metrics']['balance']:.4f}
  - ç›®æ¨™é”æˆ: {latest['balance_converged']}
  - é€£ç¶šé”æˆ: {latest['balance_metrics']['consecutive_good']}/{self.balance_patience}
  - Drawç‡: {latest['balance_metrics']['draw_rate']:.3f}

Loss Status:
  - P1 Loss: {latest['loss_metrics']['current_loss_p1']:.4f} (Best: {latest['loss_metrics']['best_loss_p1']:.4f})
  - P2 Loss: {latest['loss_metrics']['current_loss_p2']:.4f} (Best: {latest['loss_metrics']['best_loss_p2']:.4f})
  - æ”¹å–„çŠ¶æ³: P1={latest['loss_metrics']['p1_improving']}, P2={latest['loss_metrics']['p2_improving']}
  - åœæ»ã‚«ã‚¦ãƒ³ãƒˆ: {latest['loss_metrics']['plateau_count']}/{self.loss_patience}

æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:
"""

        if latest['convergence_type'] == 'optimal':
            report += "âœ… å®Ÿé¨“æˆåŠŸ! ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚’æ¨å¥¨"
        elif latest['convergence_type'] == 'early_stop_divergence':
            report += "âš ï¸ Lossç™ºæ•£ã«ã‚ˆã‚Šæ—©æœŸåœæ­¢ã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’æ¨å¥¨"
        elif latest['convergence_type'] == 'plateau_stop':
            report += "â¹ï¸ Lossåœæ»ã«ã‚ˆã‚Šåœæ­¢ã€‚ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"
        elif latest['convergence_type'] == 'training_ongoing':
            report += "â³ å­¦ç¿’ç¶™ç¶šä¸­ã€‚é€²æ—ã‚’ç›£è¦–"
        else:
            report += "ğŸ“Š çŠ¶æ³ã‚’ç¶™ç¶šç›£è¦–ä¸­"

        return report

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
    detector = EnhancedConvergenceDetector(
        balance_threshold=0.95,
        patience=10,
        loss_patience=5
    )

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("Enhanced Convergence Detector ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„:")